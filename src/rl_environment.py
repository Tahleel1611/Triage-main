import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd

class EDTriageEnv(gym.Env):
    """
    A custom Gymnasium environment for Emergency Department Triage Optimization.
    
    This environment simulates the decision-making process of a Triage Coordinator.
    It uses the predictions from the Phase 4 Hybrid Model as part of the state.
    """
    
    def __init__(self):
        super(EDTriageEnv, self).__init__()
        
        # --- Action Space ---
        # 0: Waiting Room
        # 1: Fast Track
        # 2: Acute Care Bed
        # 3: Critical Care
        # 4: Order Diagnostics (Wait)
        self.action_space = spaces.Discrete(5)
        
        # --- Observation Space ---
        # We need to define the bounds for our state vector.
        # [Patient_Probs(5), Deterioration(1), Embeddings(10), ED_State(5), Time(2)]
        # Total dims = 5 + 1 + 10 + 5 + 2 = 23
        
        # Low bounds (mostly 0)
        low = np.array([0.0]*23, dtype=np.float32)
        
        # High bounds (1.0 for probs, Inf for counts)
        high = np.array(
            [1.0]*5 +           # Pred Probs
            [1.0] +             # Deterioration Risk
            [np.inf]*10 +       # Embeddings (PCA reduced)
            [np.inf]*5 +        # ED Counts (Wait, Beds, etc)
            [1.0]*2             # Time (Sin/Cos)
        , dtype=np.float32)
        
        self.observation_space = spaces.Box(low=low, high=high, dtype=np.float32)
        
        # Simulation State
        self.current_patient_idx = 0
        self.patients_df = self._load_patient_data()
        self.num_patients = len(self.patients_df)
        
        self.ed_state = {
            'waiting': 0,
            'critical_beds': 5,
            'acute_beds': 20,
            'fast_track': 10
        }
        
    def _load_patient_data(self):
        """
        Loads the RL-ready data generated by the Hybrid Model.
        """
        try:
            # Try loading from root or src
            import os
            if os.path.exists("data/rl_ready_data_nhamcs.csv"):
                df = pd.read_csv("data/rl_ready_data_nhamcs.csv")
            elif os.path.exists("../data/rl_ready_data_nhamcs.csv"):
                df = pd.read_csv("../data/rl_ready_data_nhamcs.csv")
            else:
                # Fallback to old data if new not found
                df = pd.read_csv("../data/rl_ready_data.csv")
            
            # Load embeddings separately if needed, but for now we'll use random or just the probs
            # Ideally we merge the embeddings here too.
            # For simplicity, let's just use the probabilities and acuity.
            return df
        except FileNotFoundError:
            print("Error: rl_ready_data_nhamcs.csv not found. Using mock data.")
            return pd.DataFrame()

    def reset(self, seed=None, options=None):
        """
        Resets the environment to the start of a shift.
        """
        super().reset(seed=seed)
        
        # Reset ED State
        self.ed_state = {
            'waiting': np.random.randint(0, 10),
            'critical_beds': 5,
            'acute_beds': 20,
            'fast_track': 10
        }
        
        # Reset Patient Iterator
        self.current_patient_idx = np.random.randint(0, self.num_patients)
        self.current_patient = self._get_next_patient()
        
        observation = self._get_observation()
        info = {}
        return observation, info
    
    def step(self, action):
        """
        Execute one time step within the environment.
        """
        reward = 0
        terminated = False
        truncated = False
        info = {}
        
        # 1. Apply Action & Calculate Reward
        # Use actual acuity from data
        patient_acuity = self.current_patient['acuity'] # 1-5
        
        if action == 0: # Waiting Room
            self.ed_state['waiting'] += 1
            if patient_acuity <= 2:
                reward -= 500 # CRITICAL SAFETY PENALTY
            else:
                reward -= 1 # Minor wait penalty
                
        elif action == 3: # Critical Care
            if self.ed_state['critical_beds'] > 0:
                self.ed_state['critical_beds'] -= 1
                if patient_acuity >= 4:
                    reward -= 10 # Resource Waste
                else:
                    reward += 20 # Good catch
            else:
                reward -= 50 # Bed unavailable penalty
                self.ed_state['waiting'] += 1 # Forced to wait

        elif action == 1: # Fast Track
            if self.ed_state['fast_track'] > 0:
                self.ed_state['fast_track'] -= 1
                if patient_acuity >= 4: # ESI 4, 5
                    reward += 15 # Good allocation
                else: # ESI 1, 2, 3
                    reward -= 500 # CRITICAL SAFETY PENALTY (Under-triage)
            else:
                reward -= 5 # Wait penalty
                self.ed_state['waiting'] += 1

        elif action == 2: # Acute Care Bed
            if self.ed_state['acute_beds'] > 0:
                self.ed_state['acute_beds'] -= 1
                if patient_acuity == 2 or patient_acuity == 3:
                    reward += 15 # Correct allocation
                elif patient_acuity == 1:
                    reward -= 500 # CRITICAL SAFETY PENALTY (Should be Critical)
                else: # ESI 4, 5
                    reward -= 10 # Resource waste
            else:
                reward -= 20 # Wait penalty
                self.ed_state['waiting'] += 1

        elif action == 4: # Order Diagnostics
            reward -= 5 # Cost/Time penalty
            self.ed_state['waiting'] += 1

        
        # 2. Advance Simulation
        self.current_patient = self._get_next_patient()
        
        # Check if shift is over (mock condition)
        # In real training, we might run for N steps
        
        observation = self._get_observation()
        
        return observation, reward, terminated, truncated, info
    
    def _get_next_patient(self):
        """
        Fetches the next patient from the dataset.
        """
        if self.patients_df.empty:
             return {
                'probs': np.random.dirichlet(np.ones(5)),
                'risk': np.random.random(),
                'embedding': np.random.randn(10),
                'acuity': 3
            }
            
        # Get row
        row = self.patients_df.iloc[self.current_patient_idx]
        
        # Extract probs (prob_class_0, prob_class_1, ...)
        prob_cols = [c for c in self.patients_df.columns if 'prob_class_' in c]
        probs = row[prob_cols].values.astype(float)
        
        # Pad probs to 5 classes if model output fewer (e.g. if class 5 was missing in train)
        if len(probs) < 5:
            probs = np.pad(probs, (0, 5 - len(probs)))
            
        # Get risk if available
        risk = row['risk'] if 'risk' in row else 0.5

        patient_data = {
            'probs': probs,
            'risk': float(risk),
            'embedding': np.zeros(10), # Placeholder
            'acuity': row['acuity']
        }
        
        # Advance index (loop around)
        self.current_patient_idx = (self.current_patient_idx + 1) % self.num_patients
        
        return patient_data
        
    def _get_observation(self):
        """
        Constructs the state vector.
        """
        # Concatenate all state components
        # Probs (5) + Risk (1) + Embedding (10) + ED State (4) + Time (2) = 22
        # Wait, in __init__ we defined 23 dims.
        # Let's check ED State: waiting, critical_beds, acute_beds, fast_track = 4 items.
        # 5 + 1 + 10 + 4 + 2 = 22.
        # We need to fix the observation space definition in __init__ or add a missing feature.
        # Let's add 'average_wait_time' to ED State to make it 5 as originally planned.
        
        obs = np.concatenate([
            self.current_patient['probs'],
            [self.current_patient['risk']],
            self.current_patient['embedding'],
            list(self.ed_state.values()),
            [30.0], # Mock average wait time
            [0.5, 0.5] # Mock time
        ])
        return obs.astype(np.float32)

if __name__ == "__main__":
    # Test the environment
    env = EDTriageEnv()
    obs, _ = env.reset()
    print("Initial Observation Shape:", obs.shape)
    
    action = env.action_space.sample()
    obs, reward, term, trunc, info = env.step(action)
    print(f"Action Taken: {action}, Reward: {reward}")
